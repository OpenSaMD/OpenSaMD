{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646f237c",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RadiotherapyAI/rai/blob/b3d03beb046ba61f8cbff541cac4df0566317088/workshops/epsm-2022-ai-workshop.ipynb\" target=\"_window\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8ba2d",
   "metadata": {
    "id": "3db8ba2d"
   },
   "source": [
    "# U-Net Workshop\n",
    "\n",
    "Here is an example 2D U-Net implementation using minified data based upon creative commons dataset available at https://wiki.cancerimagingarchive.net/display/Public/HNSCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f866a",
   "metadata": {
    "id": "7a5f866a"
   },
   "outputs": [],
   "source": [
    "# Copyright (C) 2022 Radiotherapy AI Holdings Pty Ltd\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Affero General Public License as\n",
    "# published by the Free Software Foundation, either version 3 of the\n",
    "# License, or (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU Affero General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU Affero General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21387b8b-76e4-4aa8-807b-2b5f81d5cdd9",
   "metadata": {
    "id": "21387b8b-76e4-4aa8-807b-2b5f81d5cdd9"
   },
   "source": [
    "## Overview\n",
    "\n",
    "* What is possible\n",
    "  * Demonstrate the open source `rai` library\n",
    "* Building our own 2D UNet\n",
    "  * Data pipeline\n",
    "  * The pieces of a UNet\n",
    "  * Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b456a83-6c72-4f0c-8075-7e0e70a8089a",
   "metadata": {},
   "source": [
    "## What is possible with the open source `rai` library\n",
    "\n",
    "### Installing and importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f974259-0a58-4e19-a6a7-83e18a6778cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d92e1-b929-4ec9-a7b5-a8c142143a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rai==0.2.0-dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1660e-2269-4594-a9c7-2ff3d315eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "pydicom.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb08df-7356-4d45-a91d-d511581fdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rai\n",
    "rai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274307db-188d-4f42-ad74-1b133c1ac991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import raicontours\n",
    "from raicontours import TG263\n",
    "raicontours.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb21f94-01d0-4f76-8454-9438341d63de",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bd1cf-c528-4754-88a1-19fb8041b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raicontours.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd50888-89a4-4bea-8730-1325a4204c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_model = rai.load_model(cfg=raicontours.cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e43d4-ac40-443b-9805-7eee7dffa957",
   "metadata": {},
   "source": [
    "### Downloading some example DICOM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a6bf5-7935-4b13-99d0-73feb95576fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, structure_path = rai.download_deepmind_example(\"data/deepmind\")\n",
    "structure_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a52c2-7bdd-4ee6-9902-f080531f4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid, y_grid, image_stack, image_uids = rai.paths_to_image_stack_hfs(\n",
    "    image_paths\n",
    ")\n",
    "\n",
    "image_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d26b2-e639-414a-a97b-1b3970a45f4c",
   "metadata": {},
   "source": [
    "### Running the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b36d39-0a04-4652-ae67-f30e35ebbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_patch = image_stack[None, 13:77, 153:217, 228:292]\n",
    "image_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc6e4c-98a5-4c15-be41-5c74ac1e597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_masks = rai_model.predict(image_patch)\n",
    "output_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a1897-beb7-4258-abf8-bf8f0d712843",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "z = [35, 45, 55]\n",
    "y = [140, 155, 175, 195, 215, 230]\n",
    "x = [210, 230, 250, 270, 290, 310]\n",
    "\n",
    "# Workaround for https://github.com/jupyter/notebook/issues/4532\n",
    "global predicted_masks\n",
    "\n",
    "predicted_masks = rai.inference_over_jittered_grid(\n",
    "    model=rai_model, image_stack=image_stack, grid=(z, y, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26905a76-9466-4620-a967-b734c7ff2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df131d-745c-4b42-916e-1b7868ea3c82",
   "metadata": {},
   "source": [
    "### Extracting contours from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2610960-c47f-407e-af28-d039c8bd5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_contours_by_structure = rai.masks_to_contours_by_structure(\n",
    "    x_grid, y_grid, predicted_masks\n",
    ")\n",
    "\n",
    "predicted_contours_by_structure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7c01f-ae73-473f-ba63-c5569e0402ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai.plot_contours_by_structure(\n",
    "    x_grid, y_grid, image_stack, predicted_contours_by_structure\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd7ddb-f4fb-4af1-9370-f11f3d2c4100",
   "metadata": {},
   "source": [
    "### Compare results to the DICOM-RT Structure file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae5afe-fddd-485d-b2ea-ed73e13bd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_ds = pydicom.read_file(structure_path)\n",
    "[item.ROIName for item in structure_ds.StructureSetROISequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d9d1f-f76d-4a77-a240-baa4beb2fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_map = {\n",
    "    \"Orbit-Lt\": [TG263.Eye_L],\n",
    "    \"Orbit-Rt\": [TG263.Eye_R],\n",
    "    \"Lacrimal-Lt\": [TG263.Glnd_Lacrimal_L],\n",
    "    \"Lacrimal-Rt\": [TG263.Glnd_Lacrimal_R],\n",
    "    \"Lens-Lt\": [TG263.Lens_L],\n",
    "    \"Lens-Rt\": [TG263.Lens_R],\n",
    "    \"Optic-Nerve-Lt\": [TG263.OpticNrv_L],\n",
    "    \"Optic-Nerve-Rt\": [TG263.OpticNrv_R],\n",
    "    # If there was an \"Eyes\" structure, would do the following:\n",
    "    # \"Eyes\": [TG263.Eye_L, TG263.Eye_R]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a73803-96f5-48af-a3e1-4287407a5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_names = list(align_map.keys())\n",
    "structure_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104fc56-49b4-45b7-ab48-034eb1099bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_contours_by_structure = rai.dicom_to_contours_by_structure(\n",
    "    ds=structure_ds, image_uids=image_uids, structure_names=structure_names\n",
    ")\n",
    "dicom_contours_by_structure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79231a5-b6bb-41d8-953e-c19d2a3eb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_predicted_contours_by_structure = rai.merge_contours_by_structure(\n",
    "    predicted_contours_by_structure, align_map\n",
    ")\n",
    "aligned_predicted_contours_by_structure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288524c2-a52d-44cb-8f95-24dc40a0e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = {}\n",
    "for name in align_map:\n",
    "    dice[name] = rai.dice_from_contours_by_slice(\n",
    "        dicom_contours_by_structure[name],\n",
    "        aligned_predicted_contours_by_structure[name],\n",
    "    )\n",
    "\n",
    "dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f846a-8a3f-4297-b828-f9f5c5f0fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_contours_by_structure = {\n",
    "    **predicted_contours_by_structure,\n",
    "    **dicom_contours_by_structure,\n",
    "}\n",
    "\n",
    "rai.plot_contours_by_structure(\n",
    "    x_grid, y_grid, image_stack, combined_contours_by_structure, align_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852c6a7-ace4-4e39-933c-ca168156e6f1",
   "metadata": {},
   "source": [
    "## Building our own UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020af38-2575-4d06-b5b8-e8edddbf20d3",
   "metadata": {
    "id": "6020af38-2575-4d06-b5b8-e8edddbf20d3"
   },
   "source": [
    "### Library imports\n",
    "\n",
    "Here are a set of library imports, from both the standard library and some libraries downloadable from PyPI. These are imported within namespaces so as not to variable and function name conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526338b",
   "metadata": {
    "id": "0526338b"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39208213-7fcf-47c6-abb0-d6e64b58cd76",
   "metadata": {
    "id": "39208213-7fcf-47c6-abb0-d6e64b58cd76"
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fee146",
   "metadata": {
    "id": "04fee146"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "GRID_SIZE = 64\n",
    "\n",
    "DATASET_TYPES = {\"hold-out\", \"training\", \"validation\"}\n",
    "\n",
    "COLOURS_AND_LABELS = [\n",
    "    (\"#ff7f0e\", \"left parotid\"),\n",
    "    (\"#2ca02c\", \"right parotid\"),\n",
    "    (\"#d62728\", \"external\"),\n",
    "]\n",
    "NUM_CONTOURS = len(COLOURS_AND_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c771439-771d-4048-80c2-0a87cef8ac4d",
   "metadata": {
    "id": "1c771439-771d-4048-80c2-0a87cef8ac4d"
   },
   "outputs": [],
   "source": [
    "IMAGE_DIMENSIONS = (GRID_SIZE, GRID_SIZE, 1)\n",
    "MASK_DIMENSIONS = (GRID_SIZE, GRID_SIZE, NUM_CONTOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c0341-6437-4cd8-93ef-872d89929b40",
   "metadata": {
    "id": "c80c0341-6437-4cd8-93ef-872d89929b40"
   },
   "outputs": [],
   "source": [
    "EXPECTED_BATCH_IMAGE_DIMENSIONS = (\n",
    "    BATCH_SIZE,\n",
    "    *IMAGE_DIMENSIONS,\n",
    ")\n",
    "EXPECTED_BATCH_MASK_DIMENSIONS = (\n",
    "    BATCH_SIZE,\n",
    "    *MASK_DIMENSIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f980fd7",
   "metadata": {
    "id": "8f980fd7"
   },
   "source": [
    "### Download and investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041259e4-f7ad-4529-ab27-40130ffeb925",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "041259e4-f7ad-4529-ab27-40130ffeb925",
    "outputId": "f7afd9b9-453d-4fe5-a63a-2c315e1d0248"
   },
   "outputs": [],
   "source": [
    "zip_url = (\n",
    "    \"https://github.com/RadiotherapyAI/\"\n",
    "    \"unet-workshop/releases/download/\"\n",
    "    \"mini-parotid/mini-parotid.zip\"\n",
    ")\n",
    "zip_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c08ee3-4674-4489-8df9-997d7bab16ea",
   "metadata": {
    "id": "83c08ee3-4674-4489-8df9-997d7bab16ea"
   },
   "outputs": [],
   "source": [
    "# Investigate the downloadable data within a filebrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2007621",
   "metadata": {
    "id": "a2007621"
   },
   "outputs": [],
   "source": [
    "zip_filepath = \"data/hnscc.zip\"\n",
    "\n",
    "data_directory = pathlib.Path(\"data/hnscc\")\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adde864",
   "metadata": {
    "id": "5adde864"
   },
   "outputs": [],
   "source": [
    "dataset_types_found = {\n",
    "    path.name\n",
    "    for path in data_directory.glob(\"*\")\n",
    "    if path.is_dir()\n",
    "}\n",
    "\n",
    "assert dataset_types_found == DATASET_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8bf21",
   "metadata": {
    "id": "71d8bf21"
   },
   "source": [
    "### Build the TensorFlow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3986095-ed69-4cbc-904d-2ef4a0dc513d",
   "metadata": {
    "id": "d3986095-ed69-4cbc-904d-2ef4a0dc513d"
   },
   "outputs": [],
   "source": [
    "def get_image_paths(dataset_type):\n",
    "    image_paths = list(\n",
    "        (data_directory / dataset_type).glob(\n",
    "            \"*/*.image.png\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6e7df",
   "metadata": {
    "id": "34b6e7df"
   },
   "outputs": [],
   "source": [
    "def get_path_pairs(dataset_type):\n",
    "    image_paths = get_image_paths(dataset_type)\n",
    "    mask_paths = [\n",
    "        path.parent / f\"{path.name.split('.')[0]}.masks.png\"\n",
    "        for path in image_paths\n",
    "    ]\n",
    "\n",
    "    path_pairs = [\n",
    "        (str(image), str(mask))\n",
    "        for image, mask in zip(\n",
    "            image_paths,\n",
    "            mask_paths,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return sorted(path_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5a3e5",
   "metadata": {
    "id": "98c5a3e5"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load(path_pair):\n",
    "    image_path = path_pair[0]\n",
    "    masks_path = path_pair[1]\n",
    "\n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_image(\n",
    "        image_raw, channels=1, dtype=tf.uint8\n",
    "    )\n",
    "\n",
    "    masks_raw = tf.io.read_file(masks_path)\n",
    "    masks = tf.io.decode_image(\n",
    "        masks_raw, channels=NUM_CONTOURS, dtype=tf.uint8\n",
    "    )\n",
    "\n",
    "    return image / 255, masks / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ad1fb",
   "metadata": {
    "id": "cf0ad1fb"
   },
   "outputs": [],
   "source": [
    "def create_datasets(dataset_type):\n",
    "    path_pairs = get_path_pairs(dataset_type)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(path_pairs)\n",
    "    dataset = dataset.shuffle(\n",
    "        len(path_pairs),\n",
    "        reshuffle_each_iteration=True,\n",
    "    )\n",
    "    dataset = dataset.map(load)\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f761d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "230f761d",
    "outputId": "4c657c7c-0a8a-430e-c2bd-bbb084a53dad"
   },
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for dataset_type in DATASET_TYPES:\n",
    "    datasets[dataset_type] = create_datasets(dataset_type)\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e5131-7eba-441b-93e0-c3129b5f55b3",
   "metadata": {
    "id": "038e5131-7eba-441b-93e0-c3129b5f55b3"
   },
   "source": [
    "### Plotting the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fb59c",
   "metadata": {
    "id": "b02fb59c"
   },
   "outputs": [],
   "source": [
    "iterator = iter(datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b0285-607e-4710-8e4e-6ed04ec0d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_validation_images, batch_validation_masks = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015e902-450c-412e-8e1c-b7060c1074ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_validation_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46616399-3284-4d11-8f30-5b1e698acf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_validation_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b175dc-ca87-47b5-8165-d3fbfd8fc2cc",
   "metadata": {
    "id": "42b175dc-ca87-47b5-8165-d3fbfd8fc2cc"
   },
   "outputs": [],
   "source": [
    "image = batch_validation_images[0, ...]\n",
    "masks = batch_validation_masks[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804aceb2-1156-40a7-a5c8-c51dc1e852e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6198dbc-2e1f-4d53-99ae-1e04b2a194fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6065bc-c1b9-4363-84cf-4d89347048f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878663f-abc2-49bf-a1c9-52259b1f32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a5d007-b74b-40a5-a2e0-1ef471dfc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2119ac8-c1e2-4654-b9cb-4ec2b7d1c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(masks[..., 0], levels=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbce896-22cf-4723-a47b-7c56590349be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.contour(masks[..., 0], levels=[0.5], colors=[COLOURS_AND_LABELS[0][0]])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85ea3b-d46d-48bc-81bc-e8628c6e4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and generalise the above, and see if I can get the same result\n",
    "\n",
    "i = 0\n",
    "\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.contour(masks[..., i], levels=[0.5], colors=[COLOURS_AND_LABELS[i][0]])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd1553-eba6-4272-b23f-64703a059dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.contour(masks[..., i], levels=[0.5], colors=[COLOURS_AND_LABELS[i][0]])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81248ea3-9087-4d4b-90be-09050086b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.contour(masks[..., i], levels=[0.5], colors=[COLOURS_AND_LABELS[i][0]])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437d809-c6ad-4a55-915e-72e4e0eb0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a re-usable function\n",
    "\n",
    "def plot_contours(ax, image, masks):\n",
    "    ax.imshow(image[:, :, 0], cmap=\"gray\")\n",
    "\n",
    "    for i, (colour, label) in enumerate(COLOURS_AND_LABELS):\n",
    "        if np.all(masks[..., i] < 0.5) or np.all(\n",
    "            masks[..., i] > 0.5\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        c = ax.contour(\n",
    "            masks[..., i],\n",
    "            colors=[colour],\n",
    "            levels=[0.5],\n",
    "        )\n",
    "        c.collections[0].set_label(label)\n",
    "\n",
    "    ax.axis(\"equal\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bc9ae-754e-4d16-9881-5fe6acf65e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_contours(ax, image, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0b6b0-bd49-4009-8b02-cd9544ece837",
   "metadata": {
    "id": "5bc0b6b0-bd49-4009-8b02-cd9544ece837"
   },
   "source": [
    "### UNet Diagram\n",
    "\n",
    "In this section we will create a Tensorflow Keras 2D UNet model utilising a set of pre-built functions. An example UNet diagram is given below for aiding explanation:\n",
    "\n",
    "![](https://github.com/RadiotherapyAI/unet-workshop/blob/019f25013030e51b83e2370b347bf5933aebc37c/images/unet.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d76113-47a2-4417-9062-1f7e7deefc1f",
   "metadata": {},
   "source": [
    "### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fea45-464b-4eb2-ac93-fa11798581c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ee960-77b7-44c6-b184-bbe32d6ccc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation(10).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4148e3a-6a9c-4ff2-b3b3-493e7a86a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation(-5).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07ebdb-3ca0-455d-aca4-0bbc2ed82532",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 200)\n",
    "y = activation(x).numpy()\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Relu Activiation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf540c6-9b0d-4e77-9468-5950f928842e",
   "metadata": {},
   "source": [
    "\"A large number of linear combinations of linear equations, can be reduced to a single linear equation\".\n",
    "\n",
    "RELU \"breaks\" the linearity. And enables \"deep\" learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891dfcd-b1a3-4b33-aaa0-20bb0a68bcd3",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5726b4e-3178-410d-982b-d53d9582f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_image(array, vmin=-1, vmax=1):\n",
    "    plt.imshow(array, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    for (j,i), label in np.ndenumerate(array):\n",
    "        plt.text(i, j, np.round(label, decimals=2), ha='center', va='center')\n",
    "        \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d202421-d1b9-46e5-a3b8-cfd302c3872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(shape=(1,7,7,1))\n",
    "x[0,2,4,0] = 1\n",
    "\n",
    "array_image(x[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82e75d-0ef6-4f25-afb8-8204efa33a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_convolution = tf.keras.layers.Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4fa9e-8911-4b43-847c-e3cedcc775ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = example_convolution(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c60635-1421-4749-a5d7-350e79a401f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel\n",
    "example_convolution.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a911b-61d6-42b7-a66a-affccafb0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias\n",
    "example_convolution.weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333e708-1aef-4ef5-aba6-416206c4560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = example_convolution.weights[0][..., 0, 0]\n",
    "array_image(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9501574-d879-45af-bb98-1763a8f871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_image(y[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01ae09-8deb-403c-bacb-7d6662e24d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = example_convolution(y).numpy()\n",
    "array_image(z[0,...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371685d-d248-410c-b15d-a2c4845c88a0",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de17731-3fd3-4191-a668-9aa089c62373",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_max_pool = tf.keras.layers.MaxPool2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a4ba1-23b9-45b2-93b0-3e6bf25c9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4e297-0179-477b-9c9b-b0a18d0e8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_z = example_max_pool(z).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa365492-f12c-4a5b-bbb6-732603e5744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e3efc-b9ea-4c01-a5fb-04818f7c7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_image(z[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3056c-3830-4e42-92ef-6f1d8370057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_image(pooled_z[0,...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09298d-6010-4765-aa8f-52f568164f08",
   "metadata": {},
   "source": [
    "### Convolutional Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717272e-ef48-4861-ba81-343e547be67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_convolution_transpose = tf.keras.layers.Conv2DTranspose(\n",
    "    filters=1,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a0100-c54b-4175-b0bd-2c3871392c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856719a-ae49-4c46-a05b-f430fb174f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_image(x[0, ..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74331f-b93f-4f02-8de1-a0e741a831dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = example_convolution_transpose(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec08212-8ab3-48d8-81ff-e22d76e4d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b849ae9-7f49-4348-ace5-9796299f363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = example_convolution_transpose.weights[0][..., 0, 0]\n",
    "array_image(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630a022-5deb-43c8-90dc-03a50f865a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "array_image(y[0, ..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68410885-0c26-4335-9b27-73e4c9737011",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8610fb",
   "metadata": {
    "id": "1b8610fb"
   },
   "outputs": [],
   "source": [
    "def convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543ea7a",
   "metadata": {
    "id": "1543ea7a"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    \"\"\"An encoding layer within a 2D UNet\"\"\"\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    \"\"\"A decoding layer within a 2D UNet\"\"\"\n",
    "    x = conv_transpose(x, number_of_filters)\n",
    "    x = activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=-1)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25324da3-1f3d-4f2a-8611-42ac62c7ef25",
   "metadata": {
    "id": "25324da3-1f3d-4f2a-8611-42ac62c7ef25"
   },
   "outputs": [],
   "source": [
    "def get_unet_filter_counts(grid_size):\n",
    "    \"\"\"Return a reasonable set of convolution filter sizes for a UNet\"\"\"\n",
    "    network_depth = int(np.log2(grid_size / 8))\n",
    "    encoding_filter_counts = 2 ** (\n",
    "        np.array(range(network_depth)) + 5\n",
    "    )\n",
    "    decoding_filter_counts = (\n",
    "        2 ** (np.array(range(network_depth)) + 6)[::-1]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        encoding_filter_counts,\n",
    "        decoding_filter_counts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35d96f-4a92-4b79-bf6e-f9e583d2ca8a",
   "metadata": {
    "id": "6e35d96f-4a92-4b79-bf6e-f9e583d2ca8a"
   },
   "outputs": [],
   "source": [
    "def unet(grid_size, num_contours):\n",
    "    \"\"\"Create a bare-bones 2D UNet\"\"\"\n",
    "    inputs = tf.keras.layers.Input(\n",
    "        (grid_size, grid_size, 1)\n",
    "    )\n",
    "\n",
    "    (\n",
    "        encoding_filter_counts,\n",
    "        decoding_filter_counts,\n",
    "    ) = get_unet_filter_counts(grid_size)\n",
    "\n",
    "    x = inputs\n",
    "    skips = []\n",
    "\n",
    "    for number_of_filters in encoding_filter_counts:\n",
    "        x, skip = encode(x, number_of_filters)\n",
    "        skips.append(skip)\n",
    "\n",
    "    skips.reverse()\n",
    "\n",
    "    for number_of_filters, skip in zip(\n",
    "        decoding_filter_counts, skips\n",
    "    ):\n",
    "        x = decode(x, skip, number_of_filters)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        num_contours,\n",
    "        1,\n",
    "        activation=\"sigmoid\",\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a12d20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3a12d20",
    "outputId": "3d908abf-bb2a-4937-e003-8b79c5e2143c"
   },
   "outputs": [],
   "source": [
    "model = unet(GRID_SIZE, NUM_CONTOURS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677373a-5357-47e1-8ae5-df59081b6973",
   "metadata": {},
   "source": [
    "### Comparison to RAi model\n",
    "\n",
    "The model we have built above is actually very similar to the `rai` model used at the beginning of this workshop. The main difference being that the `rai` model is a 3D UNet, whereas we're building a 2D UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf66978-8106-4369-85fa-1c3ff9f22373",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37308635-7097-4144-b271-8b9c8e0efcb5",
   "metadata": {},
   "source": [
    "### Model loss (binary cross entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d527fc-16a6-4ff5-8687-e78bdfd464bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.zeros(shape=(1,7,7,1))\n",
    "gt[0,1:3,4:6,0] = 1\n",
    "\n",
    "array_image(gt[0, ..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf58838-99f9-4b93-8283-a86e23b58ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = np.copy(gt)\n",
    "pd[0,2,4,0] = 0.95\n",
    "pd[0,1,5,0] = 0\n",
    "pd[0,5,1,0] = 0.2\n",
    "pd[0,3,1,0] = 0.5\n",
    "pd[0,1,1,0] = 1\n",
    "\n",
    "array_image(pd[0, ..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d60d10-1ad5-480e-99ea-8a9e8cde00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = -(gt * np.log(pd) + (1 - gt) * np.log(1 - pd))\n",
    "array_image(bce[0, ..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316136f-666f-44ac-87ee-8132e89ed472",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.000001\n",
    "\n",
    "bce = -(gt * np.log(pd + epsilon) + (1 - gt) * np.log(1 - pd + epsilon))\n",
    "array_image(bce[0, ..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716cd14-16d8-42ba-a4f7-84c70b452fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.sum(bce)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f95e5-26be-4d8a-8afa-1e3ca19db2cd",
   "metadata": {},
   "source": [
    "### The model prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c6094",
   "metadata": {
    "id": "529c6094"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba3654-06ee-4fdf-9ca4-a76e06482ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765db8b-ffdd-4f6f-ae22-a4f8084bdd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masks = model.predict(image[None, ...])[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c836ea-da0e-4a9f-b6da-6a57f9751dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ef215-2be5-4355-8a40-8c9209dd5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e3399-91f9-4035-b5de-557850753c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "plot_contours(ax[0], image, masks)\n",
    "plot_contours(ax[1], image, pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8f781-7b72-41e2-bd92-46bc3da956a1",
   "metadata": {
    "id": "09d8f781-7b72-41e2-bd92-46bc3da956a1"
   },
   "outputs": [],
   "source": [
    "def plot_with_prediction(image, masks, pred_masks):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "    plot_contours(ax[0], image, masks)\n",
    "    plot_contours(ax[1], image, pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e787dd5-c6f5-4d15-9230-36a5f188cea1",
   "metadata": {
    "id": "4e787dd5-c6f5-4d15-9230-36a5f188cea1"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_masks = model.predict(image[None, ...])[0, ...]\n",
    "        plot_with_prediction(image, masks, pred_masks)\n",
    "\n",
    "        plt.show()\n",
    "        print(\n",
    "            \"\\nSample Prediction after\"\n",
    "            \" epoch {}\\n\".format(epoch + 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d32143-d88a-4afc-9a94-e450960ef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = DisplayCallback()\n",
    "callback.on_epoch_end(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c61a0-8800-4cb8-a26d-f2a6627b6009",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d9a31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9b8d9a31",
    "outputId": "cc9b541e-f15d-4f37-e250-f6cb57106c54"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    datasets[\"training\"],\n",
    "    epochs=50,\n",
    "    validation_data=datasets[\"validation\"],\n",
    "    callbacks=[callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a167b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "568a167b",
    "outputId": "8355e314-78dc-4cb5-c44f-ea9f0f3ad1fa"
   },
   "outputs": [],
   "source": [
    "plt.semilogy(history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.semilogy(\n",
    "    history.history[\"val_loss\"],\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "U-Net Workshop",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
